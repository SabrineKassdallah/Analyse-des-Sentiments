{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer #bibliothèque libre Python destinée à l'apprentissage automatique\nfrom sklearn.naive_bayes import BernoulliNB #naïve bayes est un type de classification bayésienne probabiliste simple basée sur le théorème de Bayes avec une forte indépendance .\nfrom sklearn.metrics import confusion_matrix#En apprentissage automatique supervisé, la matrice de confusion est une matrice qui mesure la qualité d'un système de classification. Chaque ligne correspond à une classe réelle, chaque colonne correspond à une classe estimée.\n\nimport numpy as np\nimport itertools\nimport matplotlib.pyplot as plt\nimport pandas \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_all_data():\n    root = \"Data/\"\n\n    with open(root + \"imdb_labelled.txt\", \"r\") as text_file:  #IMDb is the world's most popular and authoritative source for movie, TV and celebrity content. Find ratings and reviews for the newest movie and TV shows.\n        data = text_file.read().split('\\n')\n         \n    with open(root + \"amazon_cells_labelled.txt\", \"r\") as text_file:#site de vente en ligne \n        data += text_file.read().split('\\n')\n\n    with open(root + \"yelp_labelled.txt\", \"r\") as text_file:##User Reviews and Recommendations of Best Restaurants, Shopping, Nightlife, Food, Entertainment, Things to Do, Services and More at Yelp.\n        data += text_file.read().split('\\n')\n\n    return data\n#get_all_data()\n\n\nvalues = get_all_data()\nprint(values[0])\nprint(values[5])\nprint(values[50])\nprint(values[500])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def preprocessing_data(data):\n    processing_data = []\n    for single_data in data:\n        if len(single_data.split(\"\\t\")) == 2 and single_data.split(\"\\t\")[1] != \"\":\n            processing_data.append(single_data.split(\"\\t\"))\n\n    return processing_data\n\nall_data = get_all_data()\nvalues = preprocessing_data(all_data)\nprint(values[0])\nprint(values[10])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def split_data(data):\n    total = len(data)\n    training_ratio = 0.75\n    training_data = []\n    evaluation_data = []\n\n    for indice in range(0, total):\n        if indice < total * training_ratio:\n            training_data.append(data[indice])\n        else:\n            evaluation_data.append(data[indice])\n\n    return training_data, evaluation_data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def preprocessing_step():\n    data = get_all_data()\n    processing_data = preprocessing_data(data)\n\n    return split_data(processing_data)\ndef training_step(data, vectorizer):\n    training_text = [data[0] for data in data]\n    training_result = [data[1] for data in data]\n\n    training_text = vectorizer.fit_transform(training_text)\n\n    return BernoulliNB().fit(training_text, training_result)\n\ntraining_data, evaluation_data = preprocessing_step()\nvectorizer = CountVectorizer(binary = 'true')\nclassifier = training_step(training_data, vectorizer)\nresult = classifier.predict(vectorizer.transform([\"I love this movie!\"]))\n\nresult[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def analyse_text(classifier, vectorizer, text):\n    return text, classifier.predict(vectorizer.transform([text]))\n\nnew_result = analyse_text(classifier, vectorizer, \"Best product ever\")\nnew_result",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def print_result(result):\n    text, analysis_result = result\n    print_text = \"Positive\" if analysis_result[0] == '1' else \"Negative\"\n    print(text, \":\", print_text)\n    \nprint_result(new_result)\n\n#Best product ever : Positive\n\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Resultat de modele de training \nprint(\"Results of Training\")\n\n\nprint_result( analyse_text(classifier, vectorizer,\"this is the best movie\"))\nprint_result( analyse_text(classifier, vectorizer,\"this is the worst movie\"))\nprint_result( analyse_text(classifier, vectorizer,\"awesome!\"))\nprint_result( analyse_text(classifier, vectorizer,\"10/10\"))\nprint_result( analyse_text(classifier, vectorizer,\"so bad\"))\nprint_result( analyse_text(classifier, vectorizer,\"nice\"))\nprint_result( analyse_text(classifier, vectorizer,\"very very nice\"))\nprint_result( analyse_text(classifier, vectorizer,\"fack you\"))\nprint_result( analyse_text(classifier, vectorizer,\"you are very bad\"))\nprint_result( analyse_text(classifier, vectorizer,\"good bad\"))\nprint_result( analyse_text(classifier, vectorizer,\" bayrem is a Foolish\"))\nprint_result( analyse_text(classifier, vectorizer,\"0/0\"))\nprint_result( analyse_text(classifier, vectorizer,\"Jocker is the best film in the world\"))\n#print_result( analyse_text(classifier, vectorizer,\"\"))\n#print_result( analyse_text(classifier, vectorizer,\"\"))\n#print_result( analyse_text(classifier, vectorizer,\"\"))\n#print_result( analyse_text(classifier, vectorizer,\"\"))\n#print_result( analyse_text(classifier, vectorizer,\"\"))\n#print_result( analyse_text(classifier, vectorizer,\"\"))\n#print_result( analyse_text(classifier, vectorizer,\"\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def simple_evaluation(evaluation_data):\n    evaluation_text     = [evaluation_data[0] for evaluation_data in evaluation_data]\n    evaluation_result   = [evaluation_data[1] for evaluation_data in evaluation_data]\n\n    total = len(evaluation_text)\n    corrects = 0\n    for index in range(0, total):\n        analysis_result = analyse_text(classifier, vectorizer, evaluation_text[index])\n        text, result = analysis_result\n        corrects += 1 if result[0] == evaluation_result[index] else 0\n\n    return corrects * 100 / total\n\nsimple_evaluation(evaluation_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def create_confusion_matrix(evaluation_data):\n    evaluation_text     = [evaluation_data[0] for evaluation_data in evaluation_data]\n    actual_result       = [evaluation_data[1] for evaluation_data in evaluation_data]\n    \n    prediction_result   = []\n    for text in evaluation_text:\n        analysis_result = analyse_text(classifier, vectorizer, text)\n        prediction_result.append(analysis_result[1][0])\n        #total = [evaluation_text + actual_resultat]\n    \n    matrix = confusion_matrix(actual_result, prediction_result)\n    return matrix\n    \nconfusion_matrix_result = create_confusion_matrix(evaluation_data)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\npandas.DataFrame(confusion_matrix_result, columns=[\"Negatives\", \"Positives\"],index=[\"Negatives\", \"Positives\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "classes = [\"Negatives\", \"Positives\"]\n\nplt.figure()\nplt.imshow(confusion_matrix_result, interpolation='nearest', cmap=plt.cm.Greens)\nplt.title(\"Confusion Matrix - Sentiment Analysis\", size = 20)\nplt.colorbar()\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\n\ntext_format = 'd'\nthresh = confusion_matrix_result.max() / 2.\nfor row, column in itertools.product(range(confusion_matrix_result.shape[0]), range(confusion_matrix_result.shape[1])):\n    plt.text(column, row, format(confusion_matrix_result[row, column], text_format),\n             horizontalalignment=\"center\",\n             color=\"white\" if confusion_matrix_result[row, column] > thresh else \"black\")\n\nplt.ylabel('True label',size = 30, color='r')\nplt.xlabel('Predicted label',size = 30, color='b')\nplt.tight_layout()\n#plt.grid()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "true_negatives = confusion_matrix_result[0][0]\nfalse_negatives = confusion_matrix_result[0][1]\nfalse_positives = confusion_matrix_result[1][0]\ntrue_positives = confusion_matrix_result[1][1]\n\naccuracy = ((true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)*100)\nprecision = (true_positives / (true_positives + false_positives)*100)\nrecall = (true_positives / (true_positives + false_negatives)*100)\nf1_score = (2*(recall * precision) / (recall + precision)*100)\n\nprint('Accuracy:',\"%.2f\" %accuracy)\nprint('Precision:',\"%.2f\" %precision)\nprint('Recall:',\"%.2f\" %recall)\nprint('F1 Score:',\"%.2f\" %f1_score)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}